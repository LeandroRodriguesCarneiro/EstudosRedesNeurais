{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3aa06c5-5069-4c4c-974f-aab20e6cea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3075ee14-96cb-4455-a36d-d48df2e056a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x, derivative=False):\n",
    "    return np.ones_like(x) if derivative else x\n",
    "\n",
    "def sigmoid(x, derivative=False):\n",
    "    if derivative:\n",
    "        y = sigmoid(x)\n",
    "        return y*(1 - y)\n",
    "    return 1.0/(1.0 + np.exp(-x))\n",
    "\n",
    "def tanh(x, derivative=False):\n",
    "    if derivative:\n",
    "        y = tanh(x)\n",
    "        return 1 - y**2\n",
    "    return (np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x))\n",
    "\n",
    "def relu(x, derivative=False):\n",
    "    if derivative:\n",
    "        return np.where(x <= 0, 0, 1)\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def leaky_relu(x, derivative=False):\n",
    "    alpha = 0.1\n",
    "    if derivative:\n",
    "        return np.where(x <= 0, alpha, 1)\n",
    "    return np.where(x <= 0, alpha*x, x)\n",
    "\n",
    "def elu(x, derivative=False):\n",
    "    alpha = 1.0\n",
    "    if derivative:\n",
    "        y = elu(x)\n",
    "        return np.where(x <= 0, y + alpha, 1)\n",
    "    return np.where(x <= 0, alpha*(np.exp(x) - 1), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "551ab77d-83a6-4c2b-97c7-bbbbc082f14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, y_oh=None, derivative=False):\n",
    "    if derivative:\n",
    "        y_pred = softmax(x)\n",
    "        k = np.nonzero(y_pred * y_oh)\n",
    "        pk = y_pred[k]\n",
    "        y_pred[k] = pk * (1.0 - pk)\n",
    "        return y_pred\n",
    "    exp = np.exp(x)\n",
    "    return exp / np.sum(exp, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80f1a99d-2a01-499d-a2d5-4e9ae54039b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y, y_pred, derivative=False):\n",
    "    if derivative:\n",
    "        return np.where(y_pred > y, 1, -1) / y.shape[0]\n",
    "    else:\n",
    "        return np.mean(np.abs(y - y_pred))\n",
    "\n",
    "def mse(y, y_pred, derivative=False):\n",
    "    if derivative:\n",
    "        return -(y - y_pred) / y.shape[0]\n",
    "    else:\n",
    "        return 0.5 * np.mean((y - y_pred) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54b02971-bb2f-4ce6-8d79-effd8c2da651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy(y, y_pred, derivative=False):\n",
    "    if derivative:\n",
    "        return -(y - y_pred) / (y_pred * (1-y_pred) * y.shape[0])\n",
    "    return -np.mean(y*np.log(y_pred) + (1-y)*np.log(1-y_pred))\n",
    "\n",
    "def sigmoid_cross_entropy(y, y_pred, derivative=False):\n",
    "    y_sigmoid = sigmoid(y_pred)\n",
    "    if derivative:\n",
    "        return -(y - y_sigmoid) / y.shape[0]\n",
    "    return -np.mean(y * np.log(y_sigmoid) + (1 - y) * np.log(1 - y_sigmoid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8496388f-e6e2-4394-a7cf-2a5ac00b9b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_log_likelihood(y_oh, y_pred, derivative=False):\n",
    "    k = np.nonzero(y_pred * y_oh)\n",
    "    pk = y_pred[k]\n",
    "    if derivative:\n",
    "        y_pred[k] = (-1.0 / pk)\n",
    "        return y_pred\n",
    "    return np.mean(-np.log(pk))\n",
    "\n",
    "def softmax_neg_log_likelihood(y_oh, y_pred, derivative=False):\n",
    "    y_softmax = softmax(y_pred)\n",
    "    if derivative:\n",
    "        return -(y_oh - y_softmax) / y_oh.shape[0]    \n",
    "    return neg_log_likelihood(y_oh, y_softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01bf3863-4745-438f-900b-354b76b65a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#não utilizar metodos de inicializar com apenas zeros e uns para não ter uma rede simetrica\n",
    "def zeros(rows, columns):\n",
    "    return np.zeros((rows, columns))\n",
    "\n",
    "def ones(rows, columns):\n",
    "    return np.ones((rows, columns))\n",
    "\n",
    "#normal aleatoria\n",
    "def random_normal(rows, columns):\n",
    "    return np.random.randn(rows, columns)\n",
    "\n",
    "#uniforme aletaria\n",
    "def random_uniform(rows, columns):\n",
    "    return np.random.rand(rows, columns)\n",
    "\n",
    "#glorot uniforme quebra a simetria e converge mais rapidamente sqrt(6/(in + out))\n",
    "def glorot_uniform(rows, columns):\n",
    "    limit = np.sqrt(6/(rows + columns))\n",
    "    return 2*limit * np.random.rand(rows, columns) - limit\n",
    "\n",
    "#glorot normal quebra a simetria e converge mais rapidamente sqrt(2/(in + out))\n",
    "def glorot_normal(rows, columns):\n",
    "    std_dev = np.sqrt(2/(rows + columns))\n",
    "    return std_dev * np.random.randn(rows, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "200915e6-7713-46cc-8700-03bc702e8563",
   "metadata": {},
   "outputs": [],
   "source": [
    "#regularização L1 mata alguns neoronios, faz seleção de atributos importantes, dificil de estimar aplique apenas em casos de overfitting \n",
    "def l1_regularization(weights, derivative=False):\n",
    "    if derivative:\n",
    "        weights = [np.where(w < 0, -1, w) for w in weights]\n",
    "        return np.array([np.where(w > 0, 1, w) for w in weights])\n",
    "    return np.sum([np.sum(np.abs(w)) for w in weights])\n",
    "\n",
    "#regularização L2 nenhum atributo é mais importante, tende a diminui e espelaha valores e decaimento dos pesos, dificil de estimar aplique apenas em overfitting\n",
    "def l2_regularization(weights, derivative=False):\n",
    "    if derivative:\n",
    "        return weights\n",
    "    return 0.5 * np.sum(weights**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b5b4dd6-1899-4eac-ba56-bf34dc92a3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mini-batch divide o conjunto de treinamento em conjuntos menores, é importante dar shuffle (embaralhar) antes de cada epoch = processar todos os batch em geral é \n",
    "# a estratégia de gradiente descendente mais utilizada\n",
    "#gradiente estocastico aprende com apenass uma amostra por vez, gradiente para cada amostra, conversão lenta, anula vetorização\n",
    "#mini-batch Em geral aponta para direção que desce, converge rapido, mas não tão rapido como batch, rapida execução\n",
    "#batch gradiente aponta para direção que sempre desce, converge rapido, execução lenta\n",
    "\n",
    "def batch_sequential(x, y, batch_size = None):\n",
    "    batch_size = x.shape[0] if batch_size is None else batch_size\n",
    "    n_batchs = x.shape[0] // batch_size\n",
    "    for batch in range(n_batchs):\n",
    "        offset = batch_size * batch\n",
    "        x_batch, y_batch = x[offset:offset+batch_size], y[offset:offset+batch_size]\n",
    "        yield(x_batch,y_batch)\n",
    "\n",
    "def batch_shuffle(x, y, batch_size = None):\n",
    "    shuffle_index = np.random.permutation(range(x.shape[0]))\n",
    "    return batch_sequential(x[shuffle_index], y[shuffle_index], batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "984cb65b-d67a-474b-967f-94795133496e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning rate influencia diretamente a aprendizagem da rede, valores altos e baixos, busca decair a learning rate ao longo do tempo\n",
    "#time based menor o alpha menor a aprendizagem\n",
    "def none_decay(learnin_rate, epoch, decay_rate, decay_steps = 1):\n",
    "    return learnin_rate\n",
    "\n",
    "def time_based_decay(learnin_rate, epoch, decay_rate, decay_steps = 1):\n",
    "    return 1 / (1 + decay_rate * epoch)\n",
    "\n",
    "#exponencial maior o alpha menor aprendizagem\n",
    "def exponential_decay(learnin_rate, epoch, decay_rate, decay_steps = 1):\n",
    "    return learnin_rate * decay_rate ** epoch\n",
    "\n",
    "#stair case decaimento controlado por epochs\n",
    "def staircase_decay(learnin_rate, epoch, decay_rate, decay_steps = 1):\n",
    "    return learnin_rate * decay_rate ** (epoch // decay_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "013e6ae9-4c19-4c6d-87e5-aad4ee8c7aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchnorm_forward(layer, x, is_training=True):\n",
    "    mu = np.mean(x, axis=0) if is_training else layer._pop_mean\n",
    "    var = np.var(x, axis=0) if is_training else layer._pop_var\n",
    "    x_norm = (x - mu) / np.sqrt(var + 1e-8)\n",
    "    out = layer.gamma * x_norm + layer.beta\n",
    "\n",
    "    if is_training:\n",
    "        layer._pop_mean = layer.bn_decay * layer._pop_mean + (1.0-layer.bn_decay)*mu\n",
    "        layer._pop_var = layer.bn_decay * layer._pop_var + (1.0-layer.bn_decay)*var\n",
    "        layer._bn_cache = (x, x_norm, mu, var)\n",
    "    return out\n",
    "\n",
    "def batchnorm_backward(layer, dactivation):\n",
    "    x, x_norm, mu, var = layer._bn_cache\n",
    "\n",
    "    m = layer._activ_inp.shape[0]\n",
    "    x_mu = x - mu\n",
    "    std_inv = 1. / np.sqrt(var + 1e-8)\n",
    "\n",
    "    dx_norm = dactivation * layer.gamma\n",
    "    dvar = np.sum(dx_norm * x_mu, axis=0) * -0.5 * (std_inv**3)\n",
    "    dmu = np.sum(dx_norm * -std_inv, axis=0) + dvar * np.mean(-2.0 * x_mu, axis=0)\n",
    "\n",
    "    dx = (dx_norm * std_inv) + (dvar * 2.0 * x_mu / m) + (dmu / m)\n",
    "    layer._dgamma = np.sum(dactivation * x_norm, axis=0)\n",
    "    layer._dbeta = np.sum(dactivation, axis=0)\n",
    "    return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9e7bde3-6018-4778-92fc-0edd7ff0cb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer():\n",
    "    def __init__(self, input_dim, output_dim, activation=linear, weights_initializer=random_normal, biases_initializer=ones, dropout_prob=0, reg_func=l2_regularization, reg_strength=0, batch_norm = False, bn_decay =0.9, is_trainable = True):\n",
    "        self.input = None\n",
    "        self.weights = weights_initializer(output_dim, input_dim)\n",
    "        self.biases = biases_initializer(1, output_dim)\n",
    "        self.activation = activation\n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.reg_func = reg_func\n",
    "        self.reg_strength = reg_strength\n",
    "        self.batch_norm = batch_norm\n",
    "        self.bn_decay = bn_decay\n",
    "        self.gamma, self.beta = ones(1,output_dim), zeros(1,output_dim)\n",
    "        self.is_trainable = is_trainable\n",
    "\n",
    "        self._activ_inp, self._activ_out = None, None\n",
    "        self._dweights, self._dbiases, self._prev_dweights = None, None, 0\n",
    "        self._dropout_mask = None\n",
    "        self._dgamma, self._dbeta = None, None\n",
    "        self._pop_mean, self._pop_var = zeros(1, output_dim), zeros(1, output_dim)\n",
    "        self._bn_cache = None\n",
    "\n",
    "class NeuralNetwork():\n",
    "    def __init__(self, cost_func=mse, learning_rate=1e-3, lr_decay_method = none_decay, lr_decay_rate = 0, lr_decay_steps = 1,momentum=0, patience = np.inf):\n",
    "        self.layers = []\n",
    "        self.cost_function = cost_func\n",
    "        self.learning_rate = self.lr_initial = learning_rate\n",
    "        self.lr_decay_method = lr_decay_method\n",
    "        self.lr_decay_rate = lr_decay_rate\n",
    "        self.lr_decay_steps = lr_decay_steps\n",
    "        self.momentum = momentum\n",
    "        self.patience, self.waiting = patience, 0\n",
    "        self._best_model, self._best_loss = self.layers, np.inf\n",
    "\n",
    "    def fit(self, x_train, y_train, x_val=None, y_val=None, epochs=100, verbose=10, batch_gen=batch_sequential, batch_size=None):\n",
    "        x_val, y_val = (x_train, y_train) if (x_val is None or y_val is None) else (x_val, y_val)\n",
    "\n",
    "        for epoch in range(epochs+1):\n",
    "            self.learning_rate = self.lr_decay_method(self.lr_initial, epoch, self.lr_decay_rate, self.lr_decay_steps)\n",
    "\n",
    "            for x_batch, y_batch in batch_gen(x_train, y_train, batch_size):\n",
    "                y_pred = self.__feed_forward(x_batch)\n",
    "                self.__back_propagation(y_batch, y_pred)\n",
    "\n",
    "            loss_val = self.cost_function(y_val, self.predict(x_val))\n",
    "            if loss_val < self._best_loss:\n",
    "                self._best_model, self._best_loss = self.layers, loss_val\n",
    "                self.waiting = 0\n",
    "            else:\n",
    "                self.waiting += 1\n",
    "                if self.waiting >= self.patience:\n",
    "                    self.layers = self._best_model\n",
    "                    return\n",
    "            \n",
    "            if epoch % verbose == 0:\n",
    "                loss_train = self.cost_function(y_train, self.predict(x_train))\n",
    "                loss_reg = (1.0/y_train.shape[0])*np.sum([layer.reg_strength * layer.reg_func(layer.weights) for layer in self.layers])\n",
    "                print(\"epoch: {0:=4}/{1} loss_train: {2:.8f} + {3:.8f} = {4:.8f} loss_val = {5:.8f}\".format(epoch, epochs, loss_train, loss_reg, loss_train + loss_reg, loss_val))\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.__feed_forward(x,is_training = False)\n",
    "    \n",
    "    def save(self, file_path):\n",
    "        pkl.dump(self, open(file_path, 'wb'), -1)\n",
    "\n",
    "    def load(file_path):\n",
    "        return pkl.load(open(file_path, 'rb'))\n",
    "\n",
    "    def __feed_forward(self, x, is_training = True):\n",
    "        self.layers[0].input = x\n",
    "        for current_layer, next_layer in zip(self.layers, self.layers[1:]+[Layer(0,0)]):\n",
    "            y = np.dot(current_layer.input, current_layer.weights.T) + current_layer.biases\n",
    "            y = batchnorm_forward(current_layer, y, is_training) if current_layer.batch_norm else y\n",
    "            current_layer._dropout_mask = np.random.binomial(1, 1 - current_layer.dropout_prob, y.shape) / (1 - current_layer.dropout_prob)\n",
    "            current_layer._activ_inp = y\n",
    "            current_layer._activ_out = current_layer.activation(y) * (current_layer._dropout_mask if is_training else 1)\n",
    "            next_layer.input = current_layer._activ_out\n",
    "        return self.layers[-1]._activ_out\n",
    "    \n",
    "    def __back_propagation(self, y, y_pred):\n",
    "        last_delta = self.cost_function(y, y_pred, derivative = True)\n",
    "        for layer in reversed(self.layers):\n",
    "            d_activation = layer.activation(layer._activ_inp, derivative = True) * last_delta * layer._dropout_mask\n",
    "            d_activation = batchnorm_backward(layer, d_activation) if layer.batch_norm else d_activation\n",
    "            last_delta = np.dot(d_activation, layer.weights)\n",
    "            layer._dweights = np.dot(d_activation.T, layer.input)\n",
    "            layer._dbiases = 1.0 * d_activation.sum(axis=0, keepdims=True)\n",
    "\n",
    "        for layer in reversed(self.layers):\n",
    "            if layer.is_trainable:\n",
    "                layer._dweights = layer._dweights + (1.0/y.shape[0]) * layer.reg_strength * layer.reg_func(layer.weights, derivative=True)\n",
    "                layer._prev_dweights = -self.learning_rate * layer._dweights + self.momentum * layer._prev_dweights\n",
    "                layer.weights = layer.weights + layer._prev_dweights\n",
    "                layer.biases = layer.biases - self.learning_rate * layer._dbiases\n",
    "                \n",
    "                if layer.batch_norm:\n",
    "                    layer.gamma = layer.gamma - self.learning_rate * layer._dgamma\n",
    "                    layer.beta = layer.beta - self.learning_rate * layer._dbeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19e8f13c-f751-4dfd-b667-2f68c0fb370a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "['setosa' 'versicolor' 'virginica']\n",
      "(150, 2) (150, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f335454f490>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = load_iris()\n",
    "x, y = data.data[:, 2:], data.target.reshape(-1,1)\n",
    "\n",
    "print(data.feature_names)\n",
    "print(data.target_names)\n",
    "print(x.shape, y.shape)\n",
    "plt.scatter(x[:,0], x[:,1], c=list(np.array(y).ravel()), s=15, cmap=plt.cm.viridis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0562ed0e-03f7-4cad-95f9-074d6bfc2dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a58e2303-32f4-4b70-87a8-c3d5860167ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "onehot = OneHotEncoder(sparse_output=False)\n",
    "y_train_onehot = onehot.fit_transform(y_train)\n",
    "y_test_onehot = onehot.fit_transform(y_test)\n",
    "\n",
    "print(y_train_onehot[::20])\n",
    "print(y_test_onehot[::20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "487da99f-1d3e-4d1f-b885-e47e11980541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:    0/100000 loss_train: 1.09041896 + 0.00000000 = 1.09041896 loss_val = 1.09041896\n",
      "epoch: 10000/100000 loss_train: 0.05488485 + 0.00000000 = 0.05488485 loss_val = 0.05488485\n",
      "epoch: 20000/100000 loss_train: 0.04300669 + 0.00000000 = 0.04300669 loss_val = 0.04300669\n",
      "epoch: 30000/100000 loss_train: 0.04136648 + 0.00000000 = 0.04136648 loss_val = 0.04136648\n",
      "epoch: 40000/100000 loss_train: 0.04028546 + 0.00000000 = 0.04028546 loss_val = 0.04028546\n",
      "epoch: 50000/100000 loss_train: 0.03930726 + 0.00000000 = 0.03930726 loss_val = 0.03930726\n",
      "epoch: 60000/100000 loss_train: 0.03876633 + 0.00000000 = 0.03876633 loss_val = 0.03876633\n",
      "epoch: 70000/100000 loss_train: 0.03792968 + 0.00000000 = 0.03792968 loss_val = 0.03792968\n",
      "epoch: 80000/100000 loss_train: 0.03752750 + 0.00000000 = 0.03752750 loss_val = 0.03752750\n",
      "epoch: 90000/100000 loss_train: 0.03699461 + 0.00000000 = 0.03699461 loss_val = 0.03699461\n",
      "epoch: 100000/100000 loss_train: 0.03663756 + 0.00000000 = 0.03663756 loss_val = 0.03663756\n"
     ]
    }
   ],
   "source": [
    "input_dim, output_dim = x_train.shape[1], y_train_onehot.shape[1]\n",
    "\n",
    "# insira sua rede aqui!\n",
    "nn = NeuralNetwork(softmax_neg_log_likelihood, 1e-3)\n",
    "nn.layers.append(Layer(input_dim=input_dim, output_dim=25, activation=tanh))\n",
    "nn.layers.append(Layer(input_dim=25, output_dim=20, activation=leaky_relu))\n",
    "nn.layers.append(Layer(input_dim=20, output_dim=output_dim, activation=linear))\n",
    "nn.fit(x_train, y_train_onehot, epochs = 100000, verbose = 10000, batch_gen=batch_shuffle, batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27f68e71-8294-4405-b76b-e5249d3d14c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros encontrados:\n",
      "criterion                gini\n",
      "max_depth                 NaN\n",
      "min_samples_split           2\n",
      "min_samples_leaf            2\n",
      "max_features             log2\n",
      "accuracy             0.977778\n",
      "Name: 5, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Lista de resultados\n",
    "results = []\n",
    "\n",
    "# Iterar pelos hiperparâmetros\n",
    "for criterion in ['gini', 'entropy']:\n",
    "    for max_depth in [None, 10, 20, 30, 40, 50]:\n",
    "        for min_samples_split in [2, 5, 10]:\n",
    "            for min_samples_leaf in [1, 2, 4]:\n",
    "                for max_features in [None, 'sqrt', 'log2']:\n",
    "                    \n",
    "                    # Criar e treinar o modelo\n",
    "                    model_decision_tree = DecisionTreeClassifier(criterion=criterion, max_depth=max_depth, \n",
    "                                                                  min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, \n",
    "                                                                  max_features=max_features)\n",
    "                    model_decision_tree.fit(x_train, y_train)\n",
    "\n",
    "                    # Avaliar o modelo\n",
    "                    accuracy = model_decision_tree.score(x_test, y_test)\n",
    "                    \n",
    "                    # Salvar os resultados\n",
    "                    results.append({\n",
    "                        'criterion': criterion,\n",
    "                        'max_depth': max_depth,\n",
    "                        'min_samples_split': min_samples_split,\n",
    "                        'min_samples_leaf': min_samples_leaf,\n",
    "                        'max_features': max_features,\n",
    "                        'accuracy': accuracy\n",
    "                    })\n",
    "\n",
    "# Criar DataFrame dos resultados\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Exibir os melhores resultados\n",
    "best_results = results_df.loc[results_df['accuracy'].idxmax()]\n",
    "print(\"Melhores parâmetros encontrados:\")\n",
    "print(best_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e52a09b5-e8de-4845-b536-c03c2dfaf669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_features=&#x27;sqrt&#x27;, min_samples_split=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_features=&#x27;sqrt&#x27;, min_samples_split=5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_features='sqrt', min_samples_split=5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_decision_tree = DecisionTreeClassifier(criterion='gini', min_samples_split=5, min_samples_leaf=1, max_features='sqrt')\n",
    "model_decision_tree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23c382cd-502f-46da-a145-a89b1f227f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia da arvore de decisao: 95.56%\n",
      "Acurácia da rede neural: 95.56%\n"
     ]
    }
   ],
   "source": [
    "prevision_dicision_tree = model_decision_tree.predict(x_test)\n",
    "y_pred = np.argmax(nn.predict(x_test), axis=1)\n",
    "\n",
    "print(f'Acurácia da arvore de decisao: {(accuracy_score(y_test, prevision_dicision_tree) * 100):.2f}%')\n",
    "print('Acurácia da rede neural: {:.2f}%'.format(100*accuracy_score(y_test, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
